{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import boto3\n",
    "from boto3.session import Session\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import json\n",
    "\n",
    "%env PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sagemaker\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.processing import FrameworkProcessor, ProcessingInput, ProcessingOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = FrameworkProcessor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.2xlarge',\n",
    "    estimator_cls=SKLearn,\n",
    "    framework_version='1.0-1',\n",
    "    base_job_name='chai'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  chai-2022-09-23-08-05-59-965\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://cognomotiv-mb-chai/local', 'LocalPath': '/opt/ml/processing/input/local', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://cognomotiv-mb-chai/global', 'LocalPath': '/opt/ml/processing/main_model', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-west-2-163168668323/chai-2022-09-23-08-05-59-965/source/sourcedir.tar.gz', 'LocalPath': '/opt/ml/processing/input/code/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'entrypoint', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-west-2-163168668323/chai-2022-09-23-08-05-59-965/source/runproc.sh', 'LocalPath': '/opt/ml/processing/input/entrypoint', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'mode', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-west-2-163168668323/chai-2022-09-23-08-05-59-965/output/mode', 'LocalPath': '/opt/ml/processing/main_model/aggregated', 'S3UploadMode': 'EndOfJob'}}]\n",
      "...........................\u001b[34mFound existing installation: typing 3.7.4.3\u001b[0m\n",
      "\u001b[34mUninstalling typing-3.7.4.3:\u001b[0m\n",
      "\u001b[34m  Successfully uninstalled typing-3.7.4.3\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mCollecting pandas==1.4.3\n",
      "  Downloading pandas-1.4.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.7/11.7 MB 97.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting tensorflow==2.10.0\n",
      "  Downloading tensorflow-2.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\u001b[0m\n",
      "\u001b[34m     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 578.1/578.1 MB 2.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.1 in /miniconda3/lib/python3.8/site-packages (from pandas==1.4.3->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /miniconda3/lib/python3.8/site-packages (from pandas==1.4.3->-r requirements.txt (line 1)) (2022.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.18.5 in /miniconda3/lib/python3.8/site-packages (from pandas==1.4.3->-r requirements.txt (line 1)) (1.19.2)\u001b[0m\n",
      "\u001b[34mCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\u001b[0m\n",
      "\u001b[34mCollecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 77.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting numpy>=1.18.5\n",
      "  Downloading numpy-1.23.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.1/17.1 MB 84.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 438.7/438.7 kB 53.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting keras<2.11,>=2.10.0\n",
      "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 82.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting typing-extensions>=3.6.6\n",
      "  Downloading typing_extensions-4.3.0-py3-none-any.whl (25 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.12.0 in /miniconda3/lib/python3.8/site-packages (from tensorflow==2.10.0->-r requirements.txt (line 2)) (1.15.0)\u001b[0m\n",
      "\u001b[34mCollecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-manylinux2010_x86_64.whl (14.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.1/14.1 MB 92.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.6/42.6 kB 7.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting h5py>=2.9.0\n",
      "  Downloading h5py-3.7.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 102.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting packaging\n",
      "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.8/40.8 kB 7.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.0.1-py3-none-any.whl (5.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.5/65.5 kB 15.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting tensorflow-io-gcs-filesystem>=0.23.1\u001b[0m\n",
      "\u001b[34m  Downloading tensorflow_io_gcs_filesystem-0.27.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.4/2.4 MB 98.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools in /miniconda3/lib/python3.8/site-packages (from tensorflow==2.10.0->-r requirements.txt (line 2)) (61.2.0)\u001b[0m\n",
      "\u001b[34mCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.49.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.7/4.7 MB 105.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.14.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.0/81.0 kB 17.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting tensorboard<2.11,>=2.10\n",
      "  Downloading tensorboard-2.10.0-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[34m     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.9/5.9 MB 115.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 123.4/123.4 kB 25.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 12.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-2.0.7-py2.py3-none-any.whl (26 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel<1.0,>=0.23.0 in /miniconda3/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow==2.10.0->-r requirements.txt (line 2)) (0.37.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests<3,>=2.21.0 in /miniconda3/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0->-r requirements.txt (line 2)) (2.28.1)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.3/781.3 kB 75.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 93.3/93.3 kB 17.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 232.7/232.7 kB 40.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.11.1-py2.py3-none-any.whl (167 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 167.1/167.1 kB 30.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.9/4.9 MB 113.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting pyparsing!=3.0.5,>=2.0.2\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 98.3/98.3 kB 22.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.3/155.3 kB 30.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\u001b[0m\n",
      "\u001b[34mCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\u001b[0m\n",
      "\u001b[34mCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mCollecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-4.12.0-py3-none-any.whl (21 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /miniconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0->-r requirements.txt (line 2)) (2022.6.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<3,>=2 in /miniconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0->-r requirements.txt (line 2)) (2.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /miniconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0->-r requirements.txt (line 2)) (3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /miniconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0->-r requirements.txt (line 2)) (1.26.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.1.1 in /miniconda3/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0->-r requirements.txt (line 2)) (2.1.1)\u001b[0m\n",
      "\u001b[34mCollecting zipp>=0.5\n",
      "  Downloading zipp-3.8.1-py3-none-any.whl (5.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.1/77.1 kB 16.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.1-py3-none-any.whl (151 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 29.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mInstalling collected packages: tensorboard-plugin-wit, pyasn1, libclang, keras, flatbuffers, zipp, wrapt, werkzeug, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, pyparsing, pyasn1-modules, protobuf, oauthlib, numpy, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, pandas, packaging, opt-einsum, keras-preprocessing, importlib-metadata, h5py, google-auth, markdown, google-auth-oauthlib, tensorboard, tensorflow\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: werkzeug\n",
      "    Found existing installation: Werkzeug 0.15.6\n",
      "    Uninstalling Werkzeug-0.15.6:\n",
      "      Successfully uninstalled Werkzeug-0.15.6\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.1\n",
      "    Uninstalling protobuf-3.20.1:\n",
      "      Successfully uninstalled protobuf-3.20.1\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.2\n",
      "    Uninstalling numpy-1.19.2:\n",
      "      Successfully uninstalled numpy-1.19.2\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.3\n",
      "    Uninstalling pandas-1.1.3:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled pandas-1.1.3\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34msagemaker-inference 1.2.0 requires typing, which is not installed.\u001b[0m\n",
      "\u001b[34msagemaker-containers 2.8.6.post2 requires typing, which is not installed.\u001b[0m\n",
      "\u001b[34msagemaker-sklearn-container 2.0 requires numpy==1.19.2, but you have numpy 1.23.3 which is incompatible.\u001b[0m\n",
      "\u001b[34msagemaker-sklearn-container 2.0 requires pandas==1.1.3, but you have pandas 1.4.3 which is incompatible.\u001b[0m\n",
      "\u001b[34msagemaker-sklearn-container 2.0 requires protobuf==3.20.1, but you have protobuf 3.19.5 which is incompatible.\u001b[0m\n",
      "\u001b[34msagemaker-sklearn-container 2.0 requires Werkzeug==0.15.6, but you have werkzeug 2.2.2 which is incompatible.\u001b[0m\n",
      "\u001b[34mSuccessfully installed absl-py-1.2.0 astunparse-1.6.3 cachetools-5.2.0 flatbuffers-2.0.7 gast-0.4.0 google-auth-2.11.1 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.49.1 h5py-3.7.0 importlib-metadata-4.12.0 keras-2.10.0 keras-preprocessing-1.1.2 libclang-14.0.6 markdown-3.4.1 numpy-1.23.3 oauthlib-3.2.1 opt-einsum-3.3.0 packaging-21.3 pandas-1.4.3 protobuf-3.19.5 pyasn1-0.4.8 pyasn1-modules-0.2.8 pyparsing-3.0.9 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.10.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.27.0 termcolor-2.0.1 typing-extensions-4.3.0 werkzeug-2.2.2 wrapt-1.14.1 zipp-3.8.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2022-09-23 08:11:00.320196: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2022-09-23 08:11:00.452451: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2022-09-23 08:11:00.452479: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2022-09-23 08:11:00.479468: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[0m\n",
      "\u001b[34m2022-09-23 08:11:01.192449: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2022-09-23 08:11:01.192530: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2022-09-23 08:11:01.192537: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\u001b[0m\n",
      "\u001b[34m2.10.0\u001b[0m\n",
      "\u001b[34mlm1.h5\u001b[0m\n",
      "\u001b[34mlm2.h5\u001b[0m\n",
      "\u001b[34m['lm1.h5', 'lm2.h5']\u001b[0m\n",
      "\u001b[34m2022-09-23 08:11:02.269086: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2022-09-23 08:11:02.269126: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2022-09-23 08:11:02.269157: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-104-243.us-west-2.compute.internal): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2022-09-23 08:11:02.269505: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessor.run(\n",
    "    code='main.py',\n",
    "    source_dir='dem/',\n",
    "    #dependencies=['source/prep/pycognomotiv_prep'],\n",
    "    #00044bddd57c_1_0/VibClassifierTrainingInsightsModel.zip\n",
    "    inputs=[ProcessingInput(source='s3://cognomotiv-mb-chai/local', destination='/opt/ml/processing/input/local'),\n",
    "           ProcessingInput(source='s3://cognomotiv-mb-chai/global', destination='/opt/ml/processing/main_model')],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name='mode', source='/opt/ml/processing/main_model/aggregated')\n",
    "        #ProcessingOutput(output_name='train_input', source='/opt/ml/processing/train'),\n",
    "        #ProcessingOutput(output_name='test_input', source='/opt/ml/processing/test'),\n",
    "    ],\n",
    "    #arguments=['--max_n_per_label', '1000', '--test_size', '0.3333'],\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "/data/notebooks/takumi/CHAI/edge/mb-nvh-cim/model/variables/variables.index\n",
      "/data/notebooks/takumi/CHAI/edge/mb-nvh-cim/model/variables/variables.data-00000-of-00001\n",
      "/data/notebooks/takumi/CHAI/edge/mb-nvh-cim/model/saved_model.pb\n",
      "/data/notebooks/takumi/CHAI/edge/mb-nvh-cim/model/keras_metadata.pb\n",
      "/data/notebooks/takumi/CHAI/edge/mb-nvh-cim/scaler/scaler.txt\n",
      "/data/notebooks/takumi/CHAI/edge/mb-nvh-cim/plugin.json\n",
      "/data/notebooks/takumi/CHAI/edge/mb-nvh-cim/mb-nvh-cim.so\n",
      "/data/notebooks/takumi/CHAI/edge/mb-nvh-cim/.ipynb_checkpoints/plugin-checkpoint.json\n",
      "MD5: 01afcf9aa6040cfb35e3fa89badf6c78 (782252)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
